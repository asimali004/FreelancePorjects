# -*- coding: utf-8 -*-
"""Decision Tree Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kt4pP59G89sFcP7YzyEVZqICLCapNFSX

#1. Create a data-frame with three columns (1) Goal (2) num_donors and (3) funding_status
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_excel("Crowdfunding_data_1000_projects (3).xlsx")

df1 = df.loc[:,["Goal","num_donors","funding_status"]]

df1.head()

"""Convert values in column funding_status from text to integers (completed=1; NotCompleted=0)"""

df1["funding_status"]=np.where(df1.funding_status=="completed",1,0)
df1.head()

x = df1.iloc[:,[0,1]]
y = df1.iloc[:,2]

"""Perform 70:30 (i.e., 70% training data and remaining test data) split and create two data-frames: (1) train and (2) test. The rows must be selected randomly (2 points)"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3)

"""#2. Use train data-frame to train a decision tree model (2 points)."""

from sklearn.tree import DecisionTreeClassifier

model =  DecisionTreeClassifier()

model.fit(x_train, y_train)

"""#3. Plot the tree (2 points).




"""

from sklearn import tree

decisions = tree.export_text(model)
print(decisions)

#fig = plt.figure(figsize=(25,20))
#a= tree.plot_tree(model)

import graphviz
re = tree.export_graphviz(model)

graph = graphviz.Source(re, format="png") 
graph

"""#4. Use test data-frame to show confusion matrix and model accuracy (2 points)."""

from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix

confusion_matrix(y_test,model.predict(x_test))

plot_confusion_matrix(model, x_test, y_test)
plt.show()

model.score(x_test,y_test)# model accuracy on test data

"""#5. Perform steps 1-4 with two columns: (1) Goal and (2) funding_status, and document the change in accuracy as a comment (2 points)."""

df2 = df1.iloc[:,[0,2]]
df2.head()

x = df2.iloc[:,[0]]
y = df2.iloc[:,[1]]

x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(x,y,test_size=0.3)

model_1 =  DecisionTreeClassifier()

model_1.fit(x_train_1, y_train_1)

decisions_1 = tree.export_text(model_1)
print(decisions_1)

import graphviz
re = tree.export_graphviz(model_1)

graph = graphviz.Source(re, format="png") 
graph

confusion_matrix(y_test_1,model_1.predict(x_test_1))

plot_confusion_matrix(model_1, x_test_1, y_test_1)
plt.show()

model_1.score(x_test_1,y_test_1)# model accuracy on test data

#  In the first case we were predicting the funding status on the basis of Goals and Number of donors,
#  in this part the accuracy of the model on unseen data is 78.66%.
#  while in the second case the prediction is only based on the Goals column, when we removed a feature column and 
#  then repeat the same procedure the accuracy in that casse is 65%, that is we can say it got decreased by removing a feature column...